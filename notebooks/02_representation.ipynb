{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TextTorch - 02: Representação de Texto**\n",
    "\n",
    "**Objetivo:** Converter os textos pré-processados em vetores numéricos. Este notebook implementa a lógica para **TF-IDF** (padrão) e inclui uma seção comentada para **embeddings**, permitindo a troca fácil entre as duas abordagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Como Executar (Google Colab)**\n",
    "\n",
    "1. **Pré-requisito:** Execute o notebook `01_preprocessing.ipynb` para gerar o arquivo `artifacts/processed_dataset.pkl`.\n",
    "2. **Ambiente:** Se estiver em um novo ambiente, clone o repositório e instale as dependências.\n",
    "   ```bash\n",
    "   !git clone https://github.com/takaokensei/TextTorch.git\n",
    "   %cd TextTorch\n",
    "   !pip install -r requirements.txt\n",
    "   ```\n",
    "3. **Execução:** Execute todas as células deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 17:26:51,951 - INFO - Configuração carregada de: ../models/config.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente e dataset carregados.\n"
     ]
    }
   ],
   "source": [
    "# Imports e Configurações Iniciais\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Adiciona o diretório 'src' ao path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from representation import TFIDFRepresentation, sparse_to_dense_tensors\n",
    "from model import load_config\n",
    "\n",
    "# Carrega configurações\n",
    "CONFIG_PATH = '../models/config.yaml'\n",
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "# Carrega dataset processado\n",
    "DATASET_PATH = '../artifacts/processed_dataset.pkl'\n",
    "with open(DATASET_PATH, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(\"Ambiente e dataset carregados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Representação TF-IDF (Padrão)\n",
    "\n",
    "A abordagem padrão utiliza **TF-IDF (Term Frequency-Inverse Document Frequency)** para converter textos em vetores. Esta técnica é eficiente e funciona bem como um baseline robusto.\n",
    "\n",
    "- **`fit_transform`**: Treina o `TfidfVectorizer` no conjunto de treino.\n",
    "- **`transform`**: Aplica o vectorizer já treinado nos conjuntos de validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 17:26:55,119 - INFO - Treinando TF-IDF em 252 documentos...\n",
      "2025-11-13 17:26:55,146 - INFO - TF-IDF treinado: 676 features\n",
      "2025-11-13 17:26:55,147 - INFO - Esparsidade: 95.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão do vetor TF-IDF (features): 676\n",
      "Shape da matriz de treino: (252, 676)\n"
     ]
    }
   ],
   "source": [
    "# Inicializa o vectorizer com parâmetros do config\n",
    "tfidf_repr = TFIDFRepresentation(\n",
    "    min_df=config['min_df'],\n",
    "    max_df=config['max_df'],\n",
    "    ngram_range=tuple(config['ngram_range']),\n",
    "    max_features=config['max_features']\n",
    ")\n",
    "\n",
    "# Treina no conjunto de treino e transforma\n",
    "X_train_tfidf = tfidf_repr.fit_transform(dataset['X_train'])\n",
    "\n",
    "# Apenas transforma os conjuntos de validação e teste\n",
    "X_val_tfidf = tfidf_repr.transform(dataset['X_val'])\n",
    "X_test_tfidf = tfidf_repr.transform(dataset['X_test'])\n",
    "\n",
    "print(f\"Dimensão do vetor TF-IDF (features): {tfidf_repr.input_dim}\")\n",
    "print(f\"Shape da matriz de treino: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise das Features TF-IDF\n",
    "\n",
    "Podemos inspecionar as features (palavras e n-gramas) que o `TfidfVectorizer` aprendeu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 20 Features por IDF (mais raras e informativas) ---\n",
      "- vetor: 4.74\n",
      "- a inovacao: 4.74\n",
      "- uma revolucao: 4.74\n",
      "- ambiental e: 4.74\n",
      "- elementos: 4.74\n",
      "- ecoturismo: 4.74\n",
      "- envolvem: 4.74\n",
      "- entre diferentes: 4.74\n",
      "- energia: 4.74\n",
      "- empregos: 4.74\n",
      "- atletas de: 4.74\n",
      "- as possibilidades: 4.74\n",
      "- as estrategias: 4.74\n",
      "- territorial: 4.74\n",
      "- tecnologicas: 4.74\n",
      "- em infraestrutura: 4.74\n",
      "- e valorizacao: 4.74\n",
      "- e tecnologias: 4.74\n",
      "- e sociais: 4.74\n",
      "- e servicos: 4.74\n"
     ]
    }
   ],
   "source": [
    "top_features = tfidf_repr.get_top_features(n=20)\n",
    "print(\"--- Top 20 Features por IDF (mais raras e informativas) ---\")\n",
    "for feature, score in top_features:\n",
    "    print(f\"- {feature}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o Vectorizer\n",
    "\n",
    "Salvamos o objeto `TfidfVectorizer` treinado para uso posterior na avaliação e no deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 17:27:15,350 - INFO - Vectorizer salvo em: ../artifacts/vectorizer.joblib\n"
     ]
    }
   ],
   "source": [
    "VECTORIZER_PATH = '../artifacts/vectorizer.joblib'\n",
    "tfidf_repr.save(VECTORIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conversão para Tensores PyTorch\n",
    "\n",
    "O modelo PyTorch espera tensores como entrada. Convertemos as matrizes esparsas do TF-IDF em tensores densos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do tensor de treino: torch.Size([252, 676])\n",
      "Shape do tensor de labels de treino: torch.Size([252])\n"
     ]
    }
   ],
   "source": [
    "# Converte matrizes esparsas para tensores densos\n",
    "X_train_tensor = sparse_to_dense_tensors(X_train_tfidf)\n",
    "X_val_tensor = sparse_to_dense_tensors(X_val_tfidf)\n",
    "X_test_tensor = sparse_to_dense_tensors(X_test_tfidf)\n",
    "\n",
    "# Converte labels para tensores\n",
    "y_train_tensor = torch.tensor(dataset['y_train'], dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(dataset['y_val'], dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(dataset['y_test'], dtype=torch.long)\n",
    "\n",
    "print(f\"Shape do tensor de treino: {X_train_tensor.shape}\")\n",
    "print(f\"Shape do tensor de labels de treino: {y_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Salvando os Tensores\n",
    "\n",
    "Salvamos os tensores processados para uso nos próximos notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensores TF-IDF salvos em: ../artifacts/tensors_tfidf.pt\n"
     ]
    }
   ],
   "source": [
    "TENSORS_PATH = '../artifacts/tensors_tfidf.pt'\n",
    "\n",
    "torch.save({\n",
    "    'X_train': X_train_tensor,\n",
    "    'X_val': X_val_tensor,\n",
    "    'X_test': X_test_tensor,\n",
    "    'y_train': y_train_tensor,\n",
    "    'y_val': y_val_tensor,\n",
    "    'y_test': y_test_tensor,\n",
    "    'input_dim': tfidf_repr.input_dim,\n",
    "    'n_classes': dataset['n_classes']\n",
    "}, TENSORS_PATH)\n",
    "\n",
    "print(f\"Tensores TF-IDF salvos em: {TENSORS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **OPCIONAL: Representação com Embeddings**\n",
    "\n",
    "**Para ativar esta seção:**\n",
    "1.  **Altere a configuração:** Em `models/config.yaml`, mude `representation: tfidf` para `representation: embedding`.\n",
    "2.  **Descomente o código:** Descomente a classe `EmbeddingRepresentation` em `src/representation.py` e o código nas células abaixo.\n",
    "3.  **Reexecute este notebook.**\n",
    "\n",
    "Esta abordagem aprende uma representação densa para cada palavra, o que pode capturar melhor as relações semânticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- CÓDIGO PARA EMBEDDINGS (DESCOMENTE PARA USAR) ---\n",
    "\n",
    "# from representation import EmbeddingRepresentation\n",
    "\n",
    "# if config['representation'] == 'embedding':\n",
    "#     print(\"\\n--- Iniciando Pipeline de Embeddings ---\")\n",
    "    \n",
    "#     # 1. Construir vocabulário\n",
    "#     embedding_repr = EmbeddingRepresentation(\n",
    "#         vocab_size=config.get('vocab_size', 20000),\n",
    "#         embedding_dim=config.get('embedding_dim', 300)\n",
    "#     )\n",
    "#     embedding_repr.build_vocabulary(dataset['X_train'])\n",
    "    \n",
    "#     # 2. Converter textos para sequências de índices\n",
    "#     X_train_seq = embedding_repr.texts_to_sequences(dataset['X_train'])\n",
    "#     X_val_seq = embedding_repr.texts_to_sequences(dataset['X_val'])\n",
    "#     X_test_seq = embedding_repr.texts_to_sequences(dataset['X_test'])\n",
    "    \n",
    "#     # Labels já são tensores\n",
    "#     y_train_tensor_emb = torch.tensor(dataset['y_train'], dtype=torch.long)\n",
    "#     y_val_tensor_emb = torch.tensor(dataset['y_val'], dtype=torch.long)\n",
    "#     y_test_tensor_emb = torch.tensor(dataset['y_test'], dtype=torch.long)\n",
    "    \n",
    "#     print(f\"Shape do tensor de treino (embeddings): {X_train_seq.shape}\")\n",
    "    \n",
    "#     # 3. Salvar vocabulário e tensores\n",
    "#     VOCAB_PATH = '../artifacts/vocab.joblib'\n",
    "#     embedding_repr.save(VOCAB_PATH)\n",
    "    \n",
    "#     TENSORS_EMB_PATH = '../artifacts/tensors_embedding.pt'\n",
    "#     torch.save({\n",
    "#         'X_train': X_train_seq,\n",
    "#         'X_val': X_val_seq,\n",
    "#         'X_test': X_test_seq,\n",
    "#         'y_train': y_train_tensor_emb,\n",
    "#         'y_val': y_val_tensor_emb,\n",
    "#         'y_test': y_test_tensor_emb,\n",
    "#         'vocab_size': embedding_repr.vocab_size,\n",
    "#         'n_classes': dataset['n_classes']\n",
    "#     }, TENSORS_EMB_PATH)\n",
    "    \n",
    "#     print(f\"Vocabulário salvo em: {VOCAB_PATH}\")\n",
    "#     print(f\"Tensores de embedding salvos em: {TENSORS_EMB_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
