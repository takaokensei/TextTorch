{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TextTorch - 03: Definição do Modelo**\n",
    "\n",
    "**Objetivo:** Definir a arquitetura da rede neural que será usada para a classificação. Este notebook carrega os dados processados e instancia o modelo PyTorch conforme a configuração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Como Executar (Google Colab)**\n",
    "\n",
    "1. **Pré-requisito:** Execute os notebooks `01_preprocessing.ipynb` e `02_representation.ipynb`.\n",
    "2. **Ambiente:** Se estiver em um novo ambiente, clone o repositório e instale as dependências.\n",
    "   ```bash\n",
    "   !git clone https://github.com/takaokensei/TextTorch.git\n",
    "   %cd TextTorch\n",
    "   !pip install -r requirements.txt\n",
    "   ```\n",
    "3. **Execução:** Execute todas as células deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 17:28:59,720 - INFO - Configuração carregada de: ../models/config.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração e tensores para 'tfidf' carregados.\n"
     ]
    }
   ],
   "source": [
    "# Imports e Configurações Iniciais\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Adiciona o diretório 'src' ao path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from model import create_model, load_config\n",
    "\n",
    "# Carrega configurações\n",
    "CONFIG_PATH = '../models/config.yaml'\n",
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "# Carrega tensores processados\n",
    "TENSORS_PATH = f\"../artifacts/tensors_{config['representation']}.pt\"\n",
    "data = torch.load(TENSORS_PATH)\n",
    "\n",
    "print(f\"Configuração e tensores para '{config['representation']}' carregados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Arquitetura do Modelo (TF-IDF)\n",
    "\n",
    "Para a representação TF-IDF, usamos um classificador feedforward simples. A arquitetura é:\n",
    "\n",
    "1.  **Camada de Entrada:** `Linear(input_dim, hidden_dim)`\n",
    "    - `input_dim`: Tamanho do vocabulário TF-IDF (ex: 10.000).\n",
    "    - `hidden_dim`: Dimensão da camada oculta (ex: 512).\n",
    "2.  **Função de Ativação:** `ReLU`\n",
    "3.  **Regularização:** `Dropout` (taxa de 0.5 para evitar overfitting).\n",
    "4.  **Camada de Saída:** `Linear(hidden_dim, n_classes)`\n",
    "    - `n_classes`: Número de classes a serem preditas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 17:29:06,215 - INFO - TFIDFClassifier criado: input=676, hidden=512, output=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Arquitetura do Modelo ---\n",
      "TFIDFClassifier(\n",
      "  (fc1): Linear(in_features=676, out_features=512, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=6, bias=True)\n",
      ")\n",
      "\n",
      "Número total de parâmetros treináveis: 349,702\n"
     ]
    }
   ],
   "source": [
    "# Extrai dimensões dos dados carregados\n",
    "input_dim = data['input_dim']\n",
    "n_classes = data['n_classes']\n",
    "\n",
    "# Cria o modelo usando a factory function\n",
    "model = create_model(input_dim=input_dim, n_classes=n_classes, config=config)\n",
    "\n",
    "# Exibe a arquitetura do modelo\n",
    "print(\"--- Arquitetura do Modelo ---\")\n",
    "print(model)\n",
    "\n",
    "# Exibe o número de parâmetros treináveis\n",
    "print(f\"\\nNúmero total de parâmetros treináveis: {model.count_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Teste de Forward Pass\n",
    "\n",
    "Para garantir que o modelo está corretamente configurado, realizamos um \"forward pass\" com um pequeno batch de dados. Isso verifica se as dimensões dos tensores estão alinhadas e se o modelo produz uma saída com o formato esperado (`batch_size`, `n_classes`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testando Forward Pass ---\n",
      "Shape do tensor de entrada: torch.Size([4, 676])\n",
      "Shape do tensor de saída: torch.Size([4, 6])\n",
      "\n",
      "Forward pass concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Testando Forward Pass ---\")\n",
    "\n",
    "# Pega um pequeno batch do conjunto de treino\n",
    "X_sample = data['X_train'][:4]  # Batch de 4 amostras\n",
    "\n",
    "print(f\"Shape do tensor de entrada: {X_sample.shape}\")\n",
    "\n",
    "# Realiza o forward pass\n",
    "try:\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_sample)\n",
    "    \n",
    "    print(f\"Shape do tensor de saída: {outputs.shape}\")\n",
    "    assert outputs.shape == (4, n_classes)\n",
    "    print(\"\\nForward pass concluído com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nERRO durante o forward pass: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **OPCIONAL: Arquitetura com Embeddings**\n",
    "\n",
    "Se `representation` em `config.yaml` for `embedding`, o código abaixo definirá um modelo com uma camada de embedding e um LSTM.\n",
    "\n",
    "**Arquitetura:**\n",
    "1.  **Embedding:** `nn.Embedding(vocab_size, embedding_dim)`\n",
    "2.  **Recorrente:** `LSTM(embedding_dim, hidden_dim, bidirectional=True)`\n",
    "3.  **Regularização:** `Dropout`\n",
    "4.  **Camada de Saída:** `Linear(hidden_dim * 2, n_classes)` (x2 por ser bidirecional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CÓDIGO PARA EMBEDDINGS (EXECUTADO SE CONFIGURADO) ---\n",
    "\n",
    "# if config['representation'] == 'embedding':\n",
    "#     # Carrega os dados específicos de embedding\n",
    "#     TENSORS_EMB_PATH = '../artifacts/tensors_embedding.pt'\n",
    "#     data_emb = torch.load(TENSORS_EMB_PATH)\n",
    "    \n",
    "#     # Descomente a classe EmbeddingClassifier em src/model.py para usar\n",
    "#     try:\n",
    "#         model_emb = create_model(\n",
    "#             input_dim=data_emb['vocab_size'], # Aqui, input_dim é vocab_size\n",
    "#             n_classes=data_emb['n_classes'], \n",
    "#             config=config\n",
    "#         )\n",
    "        \n",
    "#         print(\"\\n--- Arquitetura do Modelo de Embedding ---\")\n",
    "#         print(model_emb)\n",
    "#         print(f\"\\nParâmetros treináveis: {model_emb.count_parameters():,}\")\n",
    "        \n",
    "#     except NotImplementedError as e:\n",
    "#         print(f\"\\nAVISO: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
