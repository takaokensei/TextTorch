<div align="center">
  <img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=2c4c7c&height=120&section=header"/>
  
  <a href="https://git.io/typing-svg">
    <img src="https://readme-typing-svg.herokuapp.com/?lines=TextTorch+ğŸ”¥;Modular+NLP+Pipeline;TF-IDF+%26+Embedding+Support;Academic+Reproducibility&font=Fira+Code&center=true&width=500&height=50&color=4A6FA5&vCenter=true&pause=1000&size=24" />
  </a>
  
  <br/>
  
  <samp>Pipeline completo, modular e reprodutÃ­vel para classificaÃ§Ã£o de texto acadÃªmica.</samp>
  
  <br/><br/>
  
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  </a>
  <a href="https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white"/>
  </a>
  <a href="https://github.com/takaokensei/TextTorch/blob/main/LICENSE">
    <img src="https://img.shields.io/badge/License-MIT-00C853?style=for-the-badge"/>
  </a>
</div>

<br/>

## `> about_project`

<p align="justify">
  <strong>TextTorch</strong> Ã© um framework de NLP desenvolvido para seminÃ¡rios acadÃªmicos, focado na clareza do fluxo de dados. A implementaÃ§Ã£o padrÃ£o utiliza <strong>TF-IDF</strong> para representaÃ§Ã£o esparsa e um classificador feedforward em <strong>PyTorch</strong>, mas oferece flexibilidade total para alternar para <strong>embeddings treinÃ¡veis</strong> (densos) atravÃ©s de um arquivo de configuraÃ§Ã£o centralizado.
</p>

<br/>

## `> tech_stack`

<table align="center">
  <tr>
    <td align="center" width="33%">
      <strong>ğŸ”¥ Core</strong>
      <br/><br/>
      <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white"/>
      <img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white"/>
    </td>
    <td align="center" width="33%">
      <strong>ğŸ“Š Data Processing</strong>
      <br/><br/>
      <img src="https://img.shields.io/badge/Scikit_Learn-F7931E?style=flat-square&logo=scikitlearn&logoColor=white"/>
      <img src="https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white"/>
    </td>
    <td align="center" width="33%">
      <strong>âš™ï¸ Environment</strong>
      <br/><br/>
      <img src="https://img.shields.io/badge/Google_Colab-F9AB00?style=flat-square&logo=googlecolab&logoColor=white"/>
      <img src="https://img.shields.io/badge/Jupyter-F37626?style=flat-square&logo=jupyter&logoColor=white"/>
    </td>
  </tr>
</table>

<br/>

## `> architecture`

O projeto segue uma estrutura modular rÃ­gida para garantir a separaÃ§Ã£o de responsabilidades no pipeline de ML.

```bash
TextTorch/
â”œâ”€â”€ ğŸ“‚ raw/            # Datasets brutos (ex: CSV customizado)
â”œâ”€â”€ ğŸ““ notebooks/      # Jupyter notebooks sequenciais (01-06)
â”œâ”€â”€ ğŸ“¦ src/            # LÃ³gica principal (Data Loading, Model, Train)
â”œâ”€â”€ ğŸ§  models/         # Pesos salvos e config.yaml
â”œâ”€â”€ ğŸ“Š artifacts/      # Vectorizers, plots e mÃ©tricas geradas
â”œâ”€â”€ ğŸ“‘ reports/        # RelatÃ³rios de inferÃªncia
â””â”€â”€ ğŸ“„ requirements.txt
```

<br/>

## `> quick_start`

### âš¡ OpÃ§Ã£o 1: Google Colab (Recomendado)

Ambiente com GPU gratuita e configuraÃ§Ã£o zero.

1. Acesse o [Google Colab](https://colab.research.google.com/)
2. Clone e instale em uma cÃ©lula:

```python
!git clone https://github.com/takaokensei/TextTorch.git
%cd TextTorch
!pip install -r requirements.txt
```

3. Execute os notebooks na pasta `notebooks/` sequencialmente (01 a 06)

### ğŸ› ï¸ OpÃ§Ã£o 2: ExecuÃ§Ã£o Local

**PrÃ©-requisitos:** Python 3.9+ e Git

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/takaokensei/TextTorch.git
cd TextTorch

# 2. Crie o ambiente virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Instale dependÃªncias e inicie
pip install -r requirements.txt
jupyter notebook
```

<br/>

## `> advanced_features`

### ğŸ”„ AlternÃ¢ncia TF-IDF â†” Embeddings

O TextTorch permite mudar a arquitetura do modelo editando apenas a configuraÃ§Ã£o, sem reescrever o cÃ³digo de treino.

**1. Edite a Config:**

No arquivo `models/config.yaml`, altere:

```yaml
representation: embedding  # (padrÃ£o: tfidf)
```

**2. Habilite os MÃ³dulos:**

- `src/representation.py`: Descomente `EmbeddingRepresentation`
- `src/model.py`: Descomente `EmbeddingClassifier`

**3. Re-execute:**

Rode novamente `02_representation.ipynb` (para gerar vocabulÃ¡rio) e `03_model_definition.ipynb`

<br/>

## `> output_artifacts`

ApÃ³s a execuÃ§Ã£o do pipeline, verifique a pasta `artifacts/`:

| Artefato | DescriÃ§Ã£o |
|----------|-----------|
| `processed_dataset.pkl` | Dados limpos e particionados |
| `vectorizer.joblib` | Modelo TfidfVectorizer treinado |
| `tensors_tfidf.pt` | Tensores PyTorch prontos para GPU |
| `metrics.json` | AcurÃ¡cia, F1-Score e Recall finais |
| `plots/` | Matriz de confusÃ£o e curvas de aprendizado |

<br/>

---

<div align="center">
  <samp>
    <strong>ğŸ“š Desenvolvido para seminÃ¡rios acadÃªmicos @ UFRN</strong>
    <br/>
    Modular â€¢ ReprodutÃ­vel â€¢ DidÃ¡tico
  </samp>
</div>

<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=2c4c7c&height=100&section=footer"/>
